{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74c31c13",
      "metadata": {
        "id": "74c31c13"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "corpus = [\n",
        "    \"Thor eating pizza, Loki is eating pizza, Ironman ate pizza already\",\n",
        "    \"Apple is announcing new iphone tomorrow\",\n",
        "    \"Tesla is announcing new model-3 tomorrow\",\n",
        "    \"Google is announcing new pixel-6 tomorrow\",\n",
        "    \"Microsoft is announcing new surface tomorrow\",\n",
        "    \"Amazon is announcing new eco-dot tomorrow\",\n",
        "    \"I am eating biryani and you are eating grapes\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "879fbe8e",
      "metadata": {
        "id": "879fbe8e"
      },
      "outputs": [],
      "source": [
        "#let's create the vectorizer and fit the corpus and transform them accordingly\n",
        "v = TfidfVectorizer()\n",
        "v.fit(corpus)\n",
        "transform_output = v.transform(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b5fffd2",
      "metadata": {
        "id": "4b5fffd2",
        "outputId": "7aa8ce9b-e2d3-4ff0-ceba-46b5751000bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'thor': 25, 'eating': 10, 'pizza': 22, 'loki': 17, 'is': 16, 'ironman': 15, 'ate': 7, 'already': 0, 'apple': 5, 'announcing': 4, 'new': 20, 'iphone': 14, 'tomorrow': 26, 'tesla': 24, 'model': 19, 'google': 12, 'pixel': 21, 'microsoft': 18, 'surface': 23, 'amazon': 2, 'eco': 11, 'dot': 9, 'am': 1, 'biryani': 8, 'and': 3, 'you': 27, 'are': 6, 'grapes': 13}\n"
          ]
        }
      ],
      "source": [
        "#let's print the vocabulary\n",
        "\n",
        "print(v.vocabulary_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3527afa3",
      "metadata": {
        "id": "3527afa3",
        "outputId": "e8862ade-b85b-4cd9-db36-cdcdabc8f513"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "already : 2.386294361119891\n",
            "am : 2.386294361119891\n",
            "amazon : 2.386294361119891\n",
            "and : 2.386294361119891\n",
            "announcing : 1.2876820724517808\n",
            "apple : 2.386294361119891\n",
            "are : 2.386294361119891\n",
            "ate : 2.386294361119891\n",
            "biryani : 2.386294361119891\n",
            "dot : 2.386294361119891\n",
            "eating : 1.9808292530117262\n",
            "eco : 2.386294361119891\n",
            "google : 2.386294361119891\n",
            "grapes : 2.386294361119891\n",
            "iphone : 2.386294361119891\n",
            "ironman : 2.386294361119891\n",
            "is : 1.1335313926245225\n",
            "loki : 2.386294361119891\n",
            "microsoft : 2.386294361119891\n",
            "model : 2.386294361119891\n",
            "new : 1.2876820724517808\n",
            "pixel : 2.386294361119891\n",
            "pizza : 2.386294361119891\n",
            "surface : 2.386294361119891\n",
            "tesla : 2.386294361119891\n",
            "thor : 2.386294361119891\n",
            "tomorrow : 1.2876820724517808\n",
            "you : 2.386294361119891\n"
          ]
        }
      ],
      "source": [
        "#let's print the idf of each word:\n",
        "\n",
        "all_feature_names = v.get_feature_names_out()\n",
        "\n",
        "for word in all_feature_names:\n",
        "    \n",
        "    #let's get the index in the vocabulary\n",
        "    indx = v.vocabulary_.get(word)\n",
        "    \n",
        "    #get the score\n",
        "    idf_score = v.idf_[indx]\n",
        "    \n",
        "    print(f\"{word} : {idf_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "777dfecf",
      "metadata": {
        "id": "777dfecf",
        "outputId": "8329cdba-2b6d-4288-c685-95a3b5cacdeb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Thor eating pizza, Loki is eating pizza, Ironman ate pizza already',\n",
              " 'Apple is announcing new iphone tomorrow']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4aae1030",
      "metadata": {
        "id": "4aae1030",
        "outputId": "726696a3-abee-437e-8af3-75829b43649f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.24266547, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.24266547, 0.        , 0.        ,\n",
              "        0.40286636, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.24266547, 0.11527033, 0.24266547, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.72799642, 0.        , 0.        ,\n",
              "        0.24266547, 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.30652086,\n",
              "        0.5680354 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.5680354 ,\n",
              "        0.        , 0.26982671, 0.        , 0.        , 0.        ,\n",
              "        0.30652086, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.30652086, 0.        ]])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transform_output.toarray()[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35a39ffd",
      "metadata": {
        "id": "35a39ffd",
        "outputId": "b6cade89-83e7-456c-e074-c0db6ffc68f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__setstate__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_char_ngrams',\n",
              " '_char_wb_ngrams',\n",
              " '_check_feature_names',\n",
              " '_check_n_features',\n",
              " '_check_params',\n",
              " '_check_stop_words_consistency',\n",
              " '_check_vocabulary',\n",
              " '_count_vocab',\n",
              " '_get_param_names',\n",
              " '_get_tags',\n",
              " '_limit_features',\n",
              " '_more_tags',\n",
              " '_repr_html_',\n",
              " '_repr_html_inner',\n",
              " '_repr_mimebundle_',\n",
              " '_sort_features',\n",
              " '_stop_words_id',\n",
              " '_tfidf',\n",
              " '_validate_data',\n",
              " '_validate_params',\n",
              " '_validate_vocabulary',\n",
              " '_warn_for_unused_params',\n",
              " '_white_spaces',\n",
              " '_word_ngrams',\n",
              " 'analyzer',\n",
              " 'binary',\n",
              " 'build_analyzer',\n",
              " 'build_preprocessor',\n",
              " 'build_tokenizer',\n",
              " 'decode',\n",
              " 'decode_error',\n",
              " 'dtype',\n",
              " 'encoding',\n",
              " 'fit',\n",
              " 'fit_transform',\n",
              " 'fixed_vocabulary_',\n",
              " 'get_feature_names',\n",
              " 'get_feature_names_out',\n",
              " 'get_params',\n",
              " 'get_stop_words',\n",
              " 'idf_',\n",
              " 'input',\n",
              " 'inverse_transform',\n",
              " 'lowercase',\n",
              " 'max_df',\n",
              " 'max_features',\n",
              " 'min_df',\n",
              " 'ngram_range',\n",
              " 'norm',\n",
              " 'preprocessor',\n",
              " 'set_params',\n",
              " 'smooth_idf',\n",
              " 'stop_words',\n",
              " 'stop_words_',\n",
              " 'strip_accents',\n",
              " 'sublinear_tf',\n",
              " 'token_pattern',\n",
              " 'tokenizer',\n",
              " 'transform',\n",
              " 'use_idf',\n",
              " 'vocabulary',\n",
              " 'vocabulary_']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dir(v)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}